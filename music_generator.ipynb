{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "import preprocessing\n",
    "import postprocessing\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join, isdir\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroVec = np.zeros(72,int)\n",
    "sequence_length = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data from saved files\n",
    "network_input = np.loadtxt('processed_200_filtered_net_input_final.txt', dtype=int)\n",
    "network_output = np.loadtxt('processed_200_filtered_net_output_final.txt', dtype=int)\n",
    "with open('processed_200_filtered_vocabularies_final.pkl','rb') as f: \n",
    "    str_to_int, int_to_str, count_int = pickle.load(f) #configuration to category conversions and counts \n",
    "\n",
    "print(network_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "dict_keys = [k for k,v in sorted([(k,v) for k,v in count_int.items()], key=lambda tup: tup[1])[::-1]]\n",
    "dict_vals = sorted([v for k,v in count_int.items()])[::-1]\n",
    "#show the 10 most common note configurations\n",
    "plt.bar(dict_keys[:10], dict_vals[:10], color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "n = network_input.shape[0]\n",
    "I = np.random.permutation(n)\n",
    "\n",
    "#define test and test sizes\n",
    "ntr = 20000\n",
    "nts = 5000\n",
    "\n",
    "X = network_input[I[:ntr+nts]]\n",
    "y = network_output[I[:ntr+nts]]\n",
    "\n",
    "nclass = np.maximum(np.max(X), np.max(y)) #amount of different configurations in the data\n",
    "\n",
    "#one-hot code\n",
    "X = np_utils.to_categorical(X, num_classes=nclass+1) \n",
    "y = np_utils.to_categorical(y, num_classes=nclass+1)\n",
    "\n",
    "#split to train and test\n",
    "Xtr = X[:ntr]\n",
    "ytr = y[:ntr]\n",
    "Xts = X[ntr:ntr+nts]\n",
    "yts = y[ntr:ntr+nts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train / load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = Sequential()\n",
    "final_model.add(keras.layers.LSTM(\n",
    "        3,\n",
    "        input_shape=(Xtr.shape[1], Xtr.shape[2]),\n",
    "        return_sequences=True\n",
    "    ))\n",
    "final_model.add(keras.layers.Dropout(0.3))\n",
    "final_model.add(keras.layers.LSTM(128,return_sequences=True)) #sub with catego\n",
    "final_model.add(keras.layers.Dropout(0.3))\n",
    "final_model.add(keras.layers.LSTM(128))\n",
    "final_model.add(keras.layers.Dropout(0.3))\n",
    "final_model.add(keras.layers.Dense(ytr.shape[1]))\n",
    "final_model.add(keras.layers.Activation('softmax'))\n",
    "\n",
    "\n",
    "\n",
    "pwd = os.path.dirname(os.path.realpath('__file__'))\n",
    "filepath = os.path.join(pwd, \"models\", \"weights-improvement-{epoch:02d}-{loss:.4f}-waitingModel-alldata.hdf5\")   \n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    filepath, monitor='loss', \n",
    "    verbose=1,        \n",
    "    save_best_only=True,        \n",
    "    mode='min')\n",
    "\n",
    "callbacks_list = [checkpoint]     \n",
    "\n",
    "\n",
    "# load the network weights\n",
    "\n",
    "filename = \"weights-improvement-160-1.1110-alldata_final.hdf5\"\n",
    "model_path = os.path.join(pwd, \"models\", filename)\n",
    "#final_model.load_weights(model_path) #use this line to load the weights of the pretrained model\n",
    "\n",
    "final_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "hist = final_model.fit(Xtr, ytr, epochs=400, batch_size=256, callbacks=callbacks_list, validation_data=(Xts,yts)) #use this line to train a new model\n",
    "\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "ind = random.randint(0,Xts.shape[0])\n",
    "print(\"Testing test pattern at {0}\".format(ind))\n",
    "nt = 500\n",
    "ynew = np.zeros(nt)\n",
    "pat_len = X.shape[1]\n",
    "pat = np.reshape(Xts[ind], (1,Xts.shape[1],Xts.shape[2]))\n",
    "patC = np.copy(pat)\n",
    "res = np.copy(pat)\n",
    "print(res.shape)\n",
    "for t in range(nt):\n",
    "    prob = final_model.predict(pat)\n",
    "    pred = np.argmax(prob)\n",
    "    print(pred,end=\",\")\n",
    "    newNote = np.zeros((1,1,X.shape[2]))\n",
    "    newNote[0,0,pred] = 1.0\n",
    "    pat = np.append(pat,newNote,axis=1)\n",
    "    res = np.append(res,newNote,axis=1)\n",
    "    pat = pat[:,1:sequence_length+1,:]\n",
    "\n",
    "print()\n",
    "print(res[0].shape)\n",
    "noteMat = np.zeros((res[0].shape[0],72),dtype=int)\n",
    "for veci, vec in enumerate(res[0]):\n",
    "    nextNoteInt = 0\n",
    "    for i,e in enumerate(vec):\n",
    "        if e > 0:\n",
    "            nextNoteInt = int(i)\n",
    "            break\n",
    "    noteMat[veci] = np.array([int(b) for b in int_to_str[nextNoteInt]])\n",
    "noteMat[-1] = np.zeros(72,dtype=int)\n",
    "postprocessing.convertMatToTrack(noteMat.T,32,\"prediction.mid\")\n",
    "\n",
    "\n",
    "noteMat = np.zeros((100,72),dtype=int)\n",
    "for veci, vec in enumerate(patC[0]):\n",
    "    nextNoteInt = 0\n",
    "    for i,e in enumerate(vec):\n",
    "        if e > 0:\n",
    "            nextNoteInt = int(i)\n",
    "            break\n",
    "    noteMat[veci] = np.array([int(b) for b in int_to_str[nextNoteInt]])\n",
    "noteMat[-1] = np.zeros(72,dtype=int)\n",
    "postprocessing.convertMatToTrack(noteMat.T,32,\"original.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
